{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "! pip install git+https://github.com/openai/whisper.git -q"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import whisper\n",
    "\n",
    "model = whisper.load_model(\"base\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'defines.mp3'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 6\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[39m# Load the audio file\u001b[39;00m\n\u001b[0;32m      5\u001b[0m filename \u001b[39m=\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mdefines.mp3\u001b[39m\u001b[39m\"\u001b[39m\n\u001b[1;32m----> 6\u001b[0m rate, audio_data \u001b[39m=\u001b[39m wavfile\u001b[39m.\u001b[39;49mread(filename)\n\u001b[0;32m      8\u001b[0m \u001b[39m# Display the audio\u001b[39;00m\n\u001b[0;32m      9\u001b[0m Audio(data\u001b[39m=\u001b[39maudio_data, rate\u001b[39m=\u001b[39mrate)\n",
      "File \u001b[1;32mc:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\scipy\\io\\wavfile.py:647\u001b[0m, in \u001b[0;36mread\u001b[1;34m(filename, mmap)\u001b[0m\n\u001b[0;32m    645\u001b[0m     mmap \u001b[39m=\u001b[39m \u001b[39mFalse\u001b[39;00m\n\u001b[0;32m    646\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 647\u001b[0m     fid \u001b[39m=\u001b[39m \u001b[39mopen\u001b[39;49m(filename, \u001b[39m'\u001b[39;49m\u001b[39mrb\u001b[39;49m\u001b[39m'\u001b[39;49m)\n\u001b[0;32m    649\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    650\u001b[0m     file_size, is_big_endian \u001b[39m=\u001b[39m _read_riff_chunk(fid)\n",
      "\u001b[1;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'defines.mp3'"
     ]
    }
   ],
   "source": [
    "# from IPython.display import Audio\n",
    "# from scipy.io import wavfile\n",
    "\n",
    "# # Load the audio file\n",
    "# filename = \"defines.mp3\"\n",
    "# rate, audio_data = wavfile.read(filename)\n",
    "\n",
    "# # Display the audio\n",
    "# Audio(data=audio_data, rate=rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import gradio as gr \n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transcribe(audio):\n",
    "    \n",
    "    #time.sleep(3)\n",
    "    # load audio and pad/trim it to fit 30 seconds\n",
    "    audio = whisper.load_audio(audio)\n",
    "    audio = whisper.pad_or_trim(audio)\n",
    "\n",
    "    # make log-Mel spectrogram and move to the same device as the model\n",
    "    mel = whisper.log_mel_spectrogram(audio).to(model.device)\n",
    "\n",
    "    # detect the spoken language\n",
    "    _, probs = model.detect_language(mel)\n",
    "    print(f\"Detected language: {max(probs, key=probs.get)}\")\n",
    "\n",
    "    # decode the audio\n",
    "    options = whisper.DecodingOptions()\n",
    "    result = whisper.decode(model, mel, options)\n",
    "    return result.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\vedan\\AppData\\Local\\Temp\\ipykernel_29296\\2013780087.py:5: GradioDeprecationWarning: Usage of gradio.inputs is deprecated, and will not be supported in the future, please import your component from gradio.components\n",
      "  gr.inputs.Audio(source=\"microphone\", type=\"filepath\")\n",
      "C:\\Users\\vedan\\AppData\\Local\\Temp\\ipykernel_29296\\2013780087.py:5: GradioDeprecationWarning: `optional` parameter is deprecated, and it has no effect\n",
      "  gr.inputs.Audio(source=\"microphone\", type=\"filepath\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running on local URL:  http://127.0.0.1:7860\n",
      "\n",
      "To create a public link, set `share=True` in `launch()`.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div><iframe src=\"http://127.0.0.1:7860/\" width=\"100%\" height=\"500\" allow=\"autoplay; camera; microphone; clipboard-read; clipboard-write;\" frameborder=\"0\" allowfullscreen></iframe></div>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": []
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydub\\utils.py:198: RuntimeWarning: Couldn't find ffprobe or avprobe - defaulting to ffprobe, but may not work\n",
      "  warn(\"Couldn't find ffprobe or avprobe - defaulting to ffprobe, but may not work\", RuntimeWarning)\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\processing_utils.py\", line 145, in audio_from_file\n",
      "    audio = AudioSegment.from_file(filename)\n",
      "            ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydub\\audio_segment.py\", line 728, in from_file\n",
      "    info = mediainfo_json(orig_file, read_ahead_limit=read_ahead_limit)\n",
      "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\pydub\\utils.py\", line 274, in mediainfo_json\n",
      "    res = Popen(command, stdin=stdin_parameter, stdout=PIPE, stderr=PIPE)\n",
      "          ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py\", line 1022, in __init__\n",
      "    self._execute_child(args, executable, preexec_fn, close_fds,\n",
      "  File \"c:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\subprocess.py\", line 1491, in _execute_child\n",
      "    hp, ht, pid, tid = _winapi.CreateProcess(executable, args,\n",
      "                       ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "FileNotFoundError: [WinError 2] The system cannot find the file specified\n",
      "\n",
      "The above exception was the direct cause of the following exception:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\routes.py\", line 488, in run_predict\n",
      "    output = await app.get_blocks().process_api(\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\blocks.py\", line 1428, in process_api\n",
      "    inputs = self.preprocess_data(fn_index, inputs, state)\n",
      "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\blocks.py\", line 1245, in preprocess_data\n",
      "    processed_input.append(block.preprocess(inputs[i]))\n",
      "                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\components\\audio.py\", line 220, in preprocess\n",
      "    sample_rate, data = processing_utils.audio_from_file(\n",
      "                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
      "  File \"c:\\Users\\vedan\\AppData\\Local\\Programs\\Python\\Python311\\Lib\\site-packages\\gradio\\processing_utils.py\", line 155, in audio_from_file\n",
      "    raise RuntimeError(msg) from e\n",
      "RuntimeError: Cannot load audio from file: `ffprobe` not found. Please install `ffmpeg` in your system to use non-WAV audio file formats and make sure `ffprobe` is in your PATH.\n"
     ]
    }
   ],
   "source": [
    "gr.Interface(\n",
    "    title = 'OpenAI Whisper ASR Gradio Web UI', \n",
    "    fn=transcribe, \n",
    "    inputs=[\n",
    "        gr.inputs.Audio(source=\"microphone\", type=\"filepath\")\n",
    "    ],\n",
    "    outputs=[\n",
    "        \"textbox\"\n",
    "    ],\n",
    "    live=True).launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
